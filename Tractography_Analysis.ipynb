{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ==================================================================\n",
    "# Script to analyse tractography-related statistics\n",
    "# ==================================================================\n",
    "import os\n",
    "import sys\n",
    "import glob #for wildcard matching\n",
    "import collections #for ordered dictionary\n",
    "import time\n",
    "import subprocess\n",
    "import nibabel as nib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All is well\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Anthony's notes\n",
    "- modules that needs to be loaded:\n",
    "    - qbatch/git\n",
    "    - FSL\n",
    "\n",
    "- during the initiation of the idx and pct file paths, it is ASSUMED that all input paths will:\n",
    "    - have a perfect correspondence of pct to idx paths for each subject\n",
    "        - both will appear in the same ordered after being sorted in the lists\n",
    "    - the second-to-last part deliminated by \"/\" will be the subject ID for both files\n",
    "- input file path assumptions\n",
    "    - there will be no period character (\".\") OTHER than for at the end\n",
    "    - there are two total period characters: \"filename.nii.gz\"\n",
    "\"\"\"\n",
    "print \"All is well\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ==================================================================\n",
    "# Setup files and directories\n",
    "# ==================================================================\n",
    "\n",
    "\"\"\" Note on directory hierarchy for the input, reference and transform files \n",
    "parent_dir\n",
    "    |\n",
    "    +-- subj_dir_1 (as indicated by dir_wc)\n",
    "    |        |\n",
    "    |        +- file_of_interest (as indicated by *_file_name)\n",
    "    |\n",
    "    +-- subj_dir_2 ...\n",
    "\"\"\"\n",
    "\n",
    "#Variable indication how many component parcellation we want to use\n",
    "SEG_NUM = 10\n",
    "# ========================================\n",
    "# Input files for fslmaths and fslstats\n",
    "# ========================================\n",
    "in_parent_dir='/data/chamal/projects/anthony/nmf_parcellation/cortical_tractMap/seg'+str(SEG_NUM)+'_tract2voxel_probability_labels/model_space'\n",
    "in_dir_wc='[0-9][0-9][0-9][0-9][0-9][0-9]'\n",
    "idx_file_name = '*_region_seg_idx_modelSpace.nii.gz'\n",
    "pct_file_name = '*_region_seg_pct_modelSpace.nii.gz' \n",
    "\n",
    "# ========================================\n",
    "# Intermediate files\n",
    "# ========================================\n",
    "inter_parent_dir='/data/chamal/projects/anthony/nmf_parcellation/cortical_tractMap/seg'+str(SEG_NUM)+'_tract2voxel_probability_labels/tractAnalysis_model_space'\n",
    "csvDump_filename=\"seg\"+str(SEG_NUM)+\"_avgComponentWinPct_dump.csv\"\n",
    "\n",
    "# ========================================\n",
    "# JobDoc files\n",
    "# ========================================\n",
    "jobDoc_dir='/data/chamal/projects/anthony/qbatch_jobDocs/track_analysis_related'\n",
    "jobList_path_head=os.path.join(jobDoc_dir,'autoSubmit_seg%d_tract_compWinPct'%SEG_NUM)\n",
    "jobScript_stdev_name=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The parcellation component quantity is: 10\n",
      "idx_file_list length: 100\n",
      "pct_file_list length: 100\n",
      "\n",
      "100 subjects were initiated into the subjFile_Paths dictionary:\n",
      "100307 100408 101006 101107 101410 101915 102008 102311 102816 103111 105014 105115 105216 106016 106521 107321 107422 108121 108323 108525 109123 110411 111312 111413 111716 113215 113821 113922 114419 115320 116524 117122 118528 118730 118932 119833 120212 120515 121618 122317 122620 123117 123420 123925 124422 125525 126325 126628 127630 127933 128127 128632 129028 130013 130316 131217 131722 132118 133019 133827 134324 135225 135528 136227 136833 137027 138534 139233 140925 144832 146432 147030 147737 148840 148941 149741 150423 150524 150726 151223 151526 151627 151728 153833 154734 154835 154936 156233 156637 157437 158136 159239 159340 160830 161327 161630 162228 162733 163331 164030 \n",
      "\n",
      "Hopefully the above looks right!\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================\n",
    "# Initiate paths of the two input files\n",
    "# ==================================================================\n",
    "\"\"\"Dictionary hierarchy\n",
    "subjFile_Paths\n",
    "    |\n",
    "    [\"100307\"]\n",
    "    |    |\n",
    "    |    [\"idx\"] -- path to 100307's idx file\n",
    "    |    [\"pct\"] -- path to 100307's pct file\n",
    "    |\n",
    "    [\"100408\"]\n",
    "    ...\n",
    "\"\"\"\n",
    "#Find all files on paths\n",
    "idx_file_list=glob.glob(os.path.join(in_parent_dir,in_dir_wc,idx_file_name))\n",
    "pct_file_list=glob.glob(os.path.join(in_parent_dir,in_dir_wc,pct_file_name))\n",
    "#Sort the two lists\n",
    "idx_file_list.sort()\n",
    "pct_file_list.sort()\n",
    "#Store the two files into a sorted dictionary\n",
    "subjFile_paths = collections.OrderedDict([]) #Initiate ordered dictionary\n",
    "for idx_file_path, pct_file_path in zip(idx_file_list, pct_file_list):\n",
    "    #Store the file paths in a temp dictionary\n",
    "    temp_dict = {}\n",
    "    temp_dict['idx'] = idx_file_path\n",
    "    temp_dict['pct'] = pct_file_path\n",
    "    #Check for subject ID and that they match up\n",
    "    temp_subj_ID = idx_file_path.split('/')[-2]\n",
    "    if pct_file_path.split('/')[-2] != temp_subj_ID: #If the two file IDs do not match\n",
    "        print \"Something went wrong in the pct and idx file matching for ID: %s\" % (temp_subj_ID)\n",
    "    #Add the temporary dictionary to the sorted dictionary\n",
    "    subjFile_paths[temp_subj_ID] = temp_dict\n",
    "\n",
    "#Let user know \n",
    "print \"The parcellation component quantity is: %d\" % SEG_NUM\n",
    "print \"idx_file_list length: %d\" % len(idx_file_list)\n",
    "print \"pct_file_list length: %d\" % len(pct_file_list)\n",
    "print \"\\n%d subjects were initiated into the subjFile_Paths dictionary:\" % len(subjFile_paths)\n",
    "for key in subjFile_paths:\n",
    "    print key,\n",
    "print \"\\n\\nHopefully the above looks right!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Note on Fri, June 9\n",
    "- need to write extra step to remove the thalamus mask form the tracts!\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intermediate directory not found, created one at: /data/chamal/projects/anthony/nmf_parcellation/cortical_tractMap/seg10_tract2voxel_probability_labels/tractAnalysis_model_space\n",
      "\n",
      "Opening and writing to joblist files: /data/chamal/projects/anthony/qbatch_jobDocs/track_analysis_related/autoSubmitted_seg5_tractAnalysis.sub\n",
      "\n",
      "Finished writing to joblist file\n",
      "\n",
      "Reference lists created:\n",
      "\tbinarizedComp_path_list - length: 1000\n",
      "\tpct_comp_path_list - length: 1000\n",
      "\tindv_csv_path_list - length: 100\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================\n",
    "# Generate the jobs needed to calculate everyone's component average\n",
    "# ==================================================================\n",
    "\n",
    "#Check to see if the output parent directory is present, if not create it\n",
    "if os.path.isdir(inter_parent_dir):\n",
    "    print \"Intermediate directory found: %s\" % inter_parent_dir\n",
    "else:\n",
    "    os.mkdir(inter_parent_dir)\n",
    "    print \"Intermediate directory not found, created one at: %s\"% inter_parent_dir\n",
    "\n",
    "#Create the path to the .csv file to dump all of the pct averages\n",
    "csvDump_path_tail = os.path.join(inter_parent_dir, csvDump_filename)\n",
    "\n",
    "#Create the paths to the 3 sequential files needed to get the mean\n",
    "binarize_outPath = jobList_path_head + \"_pt1-binarize.sub\"\n",
    "mul_outPath = jobList_path_head + \"_pt2-multiply.sub\"\n",
    "avgCalc_outPath = jobList_path_head + \"_pt3-calculateAverage.sub\"\n",
    "\n",
    "#Open the jobList document to write to\n",
    "print \"\\nOpening and writing to joblist files: %s\" % jobList_path\n",
    "binarize_out = open(binarize_outPath, 'w')\n",
    "mul_out = open(mul_outPath, 'w')\n",
    "avgCalc_out = open(avgCalc_outPath, 'w')\n",
    "\n",
    "#Lists to store all generated file paths for later reference (during auto-submission)\n",
    "binarizedComp_path_list = []\n",
    "pct_comp_path_list = []\n",
    "indv_csv_path_list = []\n",
    "\n",
    "#Iterate through each subject\n",
    "for subj in subjFile_paths:\n",
    "    #Check to see if the output directory is present, if not create it\n",
    "    subj_dir_path = os.path.join(inter_parent_dir, subj)\n",
    "    if not os.path.isdir(subj_dir_path):\n",
    "        os.mkdir(subj_dir_path)\n",
    "        \n",
    "    #Generate an individual csv file for this subject\n",
    "    csvDump_path = os.path.join(inter_parent_dir, str(subj)+\"_indv_\"+csvDump_filename)\n",
    "    #Store the path to the csv file for later reference\n",
    "    indv_csv_path_list.append(csvDump_path)\n",
    "    \n",
    "    #Get the input files\n",
    "    idxPath = subjFile_paths[subj]['idx']\n",
    "    pctPath = subjFile_paths[subj]['pct']\n",
    "    \n",
    "    #Iterate through each component\n",
    "    for comp_num in range(1,SEG_NUM+1):\n",
    "        #Generate the output file paths\n",
    "        binarizedComp_name = idxPath.split('/')[-1].split('.')[0]+\"_comp\"+str(comp_num)+\"_binarized.nii.gz\"\n",
    "        binarizedComp_outPath = os.path.join(subj_dir_path, binarizedComp_name )\n",
    "        pct_comp_name = pctPath.split('/')[-1].split('.')[0]+\"_comp\"+str(comp_num)+\".nii.gz\"\n",
    "        pct_comp_outPath = os.path.join(subj_dir_path, pct_comp_name )\n",
    "        \n",
    "        #Store the paths in reference lists\n",
    "        binarizedComp_path_list.append(binarizedComp_outPath)\n",
    "        pct_comp_path_list.append(pct_comp_outPath)\n",
    "        \n",
    "        #Generate the fsl commands\n",
    "        binarization='fslmaths %s -thr %d -thr %d -bin %s' % (idxPath, comp_num,comp_num, binarizedComp_outPath)\n",
    "        multiplication='fslmaths %s -mul %s %s' % (pctPath, binarizedComp_outPath, pct_comp_outPath)\n",
    "        calAvg='echo \"%s,%s,`fslstats %s -M`\" >> %s' % (subj, \"comp_\"+str(comp_num), pct_comp_outPath, csvDump_path)\n",
    "        \n",
    "        #Write the commands to the jobList file\n",
    "        binarize_out.write(binarization+\"\\n\")\n",
    "        mul_out.write(multiplication+\"\\n\")\n",
    "        avgCalc_out.write(calAvg+\"\\n\")\n",
    "\n",
    "\n",
    "\n",
    "#Close the jobList output stream\n",
    "binarize_out.close()\n",
    "mul_out.close()\n",
    "avgCalc_out.close()\n",
    "print \"\\nFinished writing to joblist file\"\n",
    "print \"\\nReference lists created:\"\n",
    "print \"\\tbinarizedComp_path_list - length: %d\" % len(binarizedComp_path_list)\n",
    "print \"\\tpct_comp_path_list - length: %d\" % len(pct_comp_path_list)\n",
    "print \"\\tindv_csv_path_list - length: %d\" % len(indv_csv_path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitting binarization job (step 1):\n",
      "qbatch -w 00:30:00 -c 1 /data/chamal/projects/anthony/qbatch_jobDocs/track_analysis_related/autoSubmit_seg10_tract_compWinPct_pt1-binarize.sub\n",
      "\n",
      "Waiting for step 1 to finish...\n",
      "All output files from previous step found!\n",
      "\n",
      "Submitting multiplication job (step 2):\n",
      "qbatch -w 00:30:00 -c 1 /data/chamal/projects/anthony/qbatch_jobDocs/track_analysis_related/autoSubmit_seg10_tract_compWinPct_pt2-multiply.sub\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================\n",
    "# Optionally submit the job sequentially to the cluster\n",
    "# ==================================================================\n",
    "\n",
    "######## Qbatch specifics ########\n",
    "SUBMIT = True\n",
    "#For the 1st and 2nd job (normal)\n",
    "CHUNKSIZE = '1' #Need each 3 lines to run sequentially\n",
    "WALLTIME = '00:30:00'\n",
    "#For the 3rd job\n",
    "CHUNKSIZE_3 = str(SEG_NUM) #Each job will be for individual subjects\n",
    "PPJ_3 = \"4\" #Needs more memory than usual\n",
    "\"\"\"This should take ~2min per line, so each job should be SEG_NUM*2min long? (guesstimated, may be shorter)\"\"\"\n",
    "\n",
    "\n",
    "#Function to wait until the previous step has been completed\n",
    "def waitLoop(prev_output_paths):\n",
    "    #Infinite loop\n",
    "    while True:\n",
    "        #Check if all output files from previous step is present\n",
    "        allFilesPresent = True\n",
    "        for path in prev_output_paths:\n",
    "            if os.path.isfile(path) != True:\n",
    "                allFilesPresent = False\n",
    "        #Either break loop or continue waiting\n",
    "        if allFilesPresent:\n",
    "            break\n",
    "        else:\n",
    "            time.sleep(5) #Currently checks every 5 seconds\n",
    "    print \"All output files from previous step found!\"\n",
    "            \n",
    "            \n",
    "#Automatically submit all 3 jobList files sequentially\n",
    "if SUBMIT:\n",
    "    ######## Step 1: submit the binarization files ########\n",
    "    print \"Submitting binarization job (step 1):\"\n",
    "    cmd = ['qbatch','-w',WALLTIME, '-c',CHUNKSIZE, binarize_outPath]\n",
    "    print ' '.join(cmd)\n",
    "    subprocess.call(cmd)\n",
    "    \n",
    "    ####### Step 2: submit the multiplciation files #######\n",
    "    #Wait until the previous jobs have been completed\n",
    "    print \"\\nWaiting for step 1 to finish...\"\n",
    "    waitLoop(binarizedComp_path_list)\n",
    "    #Submit step 2\n",
    "    print \"\\nSubmitting multiplication job (step 2):\"\n",
    "    cmd = ['qbatch','-w',WALLTIME, '-c',CHUNKSIZE, mul_outPath]\n",
    "    print ' '.join(cmd)\n",
    "    subprocess.call(cmd)\n",
    "    \n",
    "    sys.exit() #TODO: temp solution because the last steps always messes up\n",
    "                #Will do last submission locally manually\n",
    "    \n",
    "    ####### Step 3: submit the fslstats average calculation #######\n",
    "    #Wait until the previous jobs have been completed\n",
    "    print \"\\nWaiting for step 2 to finish...\"\n",
    "    waitLoop(pct_comp_path_list)\n",
    "    #Submit step 3\n",
    "    print \"\\nSubmitting average calculation job (step 3):\"\n",
    "    cmd = ['qbatch', '-c', CHUNKSIZE_3, '--ppj', PPJ_3, avgCalc_outPath]\n",
    "    print ' '.join(cmd)\n",
    "    subprocess.call(cmd)\n",
    "    print\n",
    "else:\n",
    "    print \"Auto-submit not enabled. Skipping over current code block.\"\n",
    "    \n",
    "\n",
    "print \"Done\"    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The below block is independent, other than for the first (module import) block\n"
     ]
    }
   ],
   "source": [
    "####################################################################\n",
    "# ==================================================================\n",
    "\"\"\" =================== DEPENDENCY SEPARATOR =================== \"\"\"\n",
    "# ==================================================================\n",
    "####################################################################\n",
    "print \"The below block is independent, other than for the first (module import) block\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File paths found: 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-117-a3b4929770b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"File paths found: %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindv_csv_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"\\nFirst path is: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mindv_csv_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"\\nLast path is: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mindv_csv_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# ==================================================================\n",
    "# Set up input directories and paths\n",
    "# *currently dependent on the prev file input block\n",
    "# *can simply take away the right-hand-side variables for manual input\n",
    "# ==================================================================\n",
    "\"\"\"Notes on file formats\n",
    "- The 2nd col of the .csv file ALWAYS specifies the component #\n",
    "    - Specified as a string\n",
    "    - Needs to be the same for all subj's same components\n",
    "- The 3rd col of the .csv file ALWAYS specifies the mean\n",
    "    - It needs to be able to be converted to a float\n",
    "\"\"\"\n",
    "#Additional imports\n",
    "import csv\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#specify parcellation quantity\n",
    "SEG_NUM = 6\n",
    "\n",
    "#Paths set-up\n",
    "indv_csv_dir = '/data/chamal/projects/anthony/nmf_parcellation/cortical_tractMap/seg'+str(SEG_NUM)+'_tract2voxel_probability_labels/tractAnalysis_model_space'\n",
    "indv_csv_wc = \"*seg\"+str(SEG_NUM)+\"_avgComponentWinPct_dump.csv\"\n",
    "\n",
    "# ==================================================================\n",
    "# Find and initiate input files\n",
    "# ==================================================================\n",
    "\n",
    "#Locate and sort file paths \n",
    "indv_csv_paths = glob.glob(os.path.join(indv_csv_dir, indv_csv_wc))\n",
    "indv_csv_paths.sort()\n",
    "\n",
    "print \"File paths found: %d\" % len(indv_csv_paths)\n",
    "print \"\\nFirst path is: %s\" % indv_csv_paths[0]\n",
    "print \"\\nLast path is: %s\" % indv_csv_paths[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initiating .csv file contents...\n",
      "Sorting component lexographically...\n",
      "\n",
      "Done. Below are the components and length of lists for each:\n",
      "\tcomp_1\tLength: 100\n",
      "\tcomp_2\tLength: 100\n",
      "\tcomp_3\tLength: 100\n",
      "\tcomp_4\tLength: 100\n",
      "\tcomp_5\tLength: 100\n"
     ]
    }
   ],
   "source": [
    "# ==================================================================\n",
    "# Find and initiate input files\n",
    "# ==================================================================\n",
    "\"\"\"Variable hierarchy\n",
    "tractWinPct\n",
    "    |\n",
    "    [0]-- component 1's tract win pct\n",
    "            (this is a list of average winPct in float)\n",
    "\"\"\"\n",
    "\n",
    "#Initiate a dictionary \n",
    "tractWinPct_unordered = {}\n",
    "\n",
    "#Iterate through each subject's csv file\n",
    "print \"Initiating .csv file contents...\"\n",
    "for csv_path in indv_csv_paths:\n",
    "    #Open the file and initate reader\n",
    "    csvfile = open(csv_path, 'rb')\n",
    "    reader = csv.reader(csvfile)\n",
    "    #Iterate through each row of the csv file\n",
    "    for row in reader:\n",
    "        #If the component num has not been initiated, initiate the key\n",
    "        if row[1] not in tractWinPct_unordered:\n",
    "            tractWinPct_unordered[row[1]] = [float(row[2])]\n",
    "        #Else, concatenate the mean onto the list\n",
    "        else:\n",
    "            tractWinPct_unordered[row[1]].append(float(row[2]))\n",
    "\n",
    "#Initiate a sorted dictionary\n",
    "print \"Sorting component lexographically...\"\n",
    "tractWinPct = collections.OrderedDict(sorted(tractWinPct_unordered.items()))\n",
    "\n",
    "#Let user know\n",
    "print \"\\nDone. Below are the components and length of lists for each:\"\n",
    "for key in tractWinPct:\n",
    "    print \"\\t%s\\tLength: %d\" % (key, len(tractWinPct[key]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAecAAAFJCAYAAAChG+XKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAGNtJREFUeJzt3WFsG/X9x/GPay8twQ0OyHlGs7qKVSQeBLMJIeGWiaVA\nJTYmhSTtlHQqD0ZVidFmtFCpUaaELFUqBQ2pCWNDlSJUsg2GkidsytItLJsqiOIha2mKEOpEWrWG\nOGodd0tc3/8Bm7uu/8ZJ6vP9fH2/JKQevvv5e9+0+fh+Pv/ssSzLEgAAMMYapwsAAADXI5wBADAM\n4QwAgGEIZwAADEM4AwBgGMIZAADD+Jwu4D8SictOl7AilZXlSibTTpfhevTZfvTYfvS4OEqtz8Hg\n+ps+xpXzKvl8XqdLuC3QZ/vRY/vR4+JwU58JZwAADEM4AwBgGMIZAADDEM4AABiGcAYAwDCEMwAA\nhiGcAQAwDOEMAIBhCGcAAAxDOAMAYBjCGQAAwxDOAAAYhnAGAMAwhDMAAIYhnAEAMAzhDACAYQhn\nAAAMQzgDAGAYwhkAAMMQzgAAGIZwBgDAMIQzAACGIZwBADCML98O2WxW7e3tmp6eVllZmTo7O1Vd\nXS1JSiQS2r9/f27fqakptba2qr6+Xi+99JJmZma0Zs0adXR0aNOmTfadBQAALpI3nEdGRrSwsKDB\nwUHFYjF1d3err69PkhQMBjUwMCBJmpycVG9vrxoaGnTy5EllMhm9/fbbGh8f16uvvqrXXnvN3jMB\nALjKli0P6fTpKVvG3rz5Po2NnbJl7ELIG84TExOKRqOSpNraWsXj8Rv2sSxLHR0dOnr0qLxerzZu\n3KirV68qm80qlUrJ58v7NAAAXGel4VlVVaGLFy/ZVE1x5U3NVColv9+f2/Z6vcpkMtcF7ujoqGpq\nahQKhSRJ5eXlmpmZ0ZNPPqlkMqn+/n4bSgcAwJ3yhrPf79f8/HxuO5vN3nAlPDQ0pJaWltz28ePH\n9cgjj6i1tVXnz5/Xrl27NDw8rLVr1970eSory+XzeVdzDo4JBtc7XcJtgT7bjx7bjx4Xh1v6nDec\nI5GITp48qe3btysWiykcDt+wTzweVyQSyW1XVFToa1/7miTprrvuUiaT0dWrV5d8nmQyvdLaHRUM\nrlcicdnpMlyPPtuPHtuPHhdPKfV5qRcSecO5rq5O4+PjampqkmVZ6urq0vDwsNLptBobGzU7Oyu/\n3y+Px5M75gc/+IEOHTqknTt3anFxUfv27VN5eXlhzgYAAJfzWJZlOV2EVFqvdiReCRcLfbYfPbYf\nPS6OUrshbKkrZxYhAQDAMIQzAACGIZwBADAM4QwAgGEIZwAADEM4AwBgGMIZAADDEM4AABiGcAYA\nwDCEMwAAhiGcAQAwDOEMAIBhCGcAAAxDOAMAYBjCGQAAwxDOAAAYhnAGAMAwhDMAAIYhnAEAMAzh\nDACAYQhnAAAMQzgDAGAYwhkAAMMQzgAAGIZwBgDAMIQzAACGIZwBADAM4QwAgGEIZwAADEM4AwBg\nGMIZAADDEM4AABiGcAYAwDCEMwAAhiGcAQAwjC/fDtlsVu3t7ZqenlZZWZk6OztVXV0tSUokEtq/\nf39u36mpKbW2tmrHjh16/fXXNTo6qsXFRe3YsUPPPPOMfWcBAICL5A3nkZERLSwsaHBwULFYTN3d\n3err65MkBYNBDQwMSJImJyfV29urhoYGnTp1SpOTkzpx4oSuXLmiN998096zAADARfKG88TEhKLR\nqCSptrZW8Xj8hn0sy1JHR4eOHj0qr9erP//5zwqHw9q7d69SqZQOHDhQ+MoBAHCpvOGcSqXk9/tz\n216vV5lMRj7ftUNHR0dVU1OjUCgkSUomkzp37pz6+/v1+eefa8+ePXr//ffl8Xhu+jyVleXy+by3\nci5FFwyud7qE2wJ9th89th89Lg639DlvOPv9fs3Pz+e2s9nsdcEsSUNDQ2ppacltBwIBhUIhlZWV\nKRQKae3atZqdndU999xz0+dJJtOrqd8xweB6JRKXnS7D9eiz/eix/ehx8ZRSn5d6IZH3bu1IJKKx\nsTFJUiwWUzgcvmGfeDyuSCSS237wwQf1wQcfyLIsXbhwQVeuXFEgEFhN7QAA3HbyXjnX1dVpfHxc\nTU1NsixLXV1dGh4eVjqdVmNjo2ZnZ+X3+6+bsv7Wt76lDz/8UPX19bIsS21tbfJ6S2vKGgAAp3gs\ny7KcLkIqrakIiWmqYqHP9qPH9qPHxVFVVaGLFy85Xcay3dK0NgAAKC7CGQAAwxDOAAAYhnAGAMAw\nhDMAAIYhnAEAMAzhDACAYQhnAAAMQzgDAGAYwhkAAMMQzgAAGIZwBgDAMIQzAACGIZwBADAM4QwA\ngGEIZwAADEM4AwBgGMIZAADDEM4AABiGcAYAwDCEMwAAhiGcAQAwDOEMAIBhCGcAAAxDOAMAYBif\n0wUAAG4f4fAGzc3N2TZ+VVVFwccMBAI6c+YfBR93KYQzAKBo5ubmdPHiJVvGDgbXK5G4XPBx7Qj8\nfJjWBgDAMIQzAACGYVobRbdly0M6fXqq4ONu3nyfxsZOFXxcACg2whlFt5IAraqqsO39KQAwFdPa\nAAAYhnAGAMAwhDMAAIYhnAEAMEzecM5ms2pra1NjY6Oam5t19uzZ3GOJRELNzc25/77xjW/oxIkT\nuce//PJLbd26VZ9++qk91QMA4EJ579YeGRnRwsKCBgcHFYvF1N3drb6+PklSMBjUwMCAJGlyclK9\nvb1qaGiQJC0uLqqtrU3r1q2zsXwAANwn75XzxMSEotGoJKm2tlbxePyGfSzLUkdHh9rb2+X1eiVJ\nR44cUVNTk6qqqgpcMgAA7pb3yjmVSsnv9+e2vV6vMpmMfL5rh46OjqqmpkahUEiS9O677+ruu+9W\nNBrVz3/+82UVUllZLp/Pu9L6HRUMrne6hNsCfbYfPbYfPb7Gzl7YNXaxf355w9nv92t+fj63nc1m\nrwtmSRoaGlJLS0tu+5133pHH49Ff//pXTU1N6eDBg+rr61MwGLzp8yST6dXU7xi7FljHjeizvfi7\nbD96fD27emFnn+0Yd6nAzxvOkUhEJ0+e1Pbt2xWLxRQOh2/YJx6PKxKJ5Lbfeuut3J+bm5vV3t6+\nZDCbwq5lJSWWlgQALF/ecK6rq9P4+LiamppkWZa6uro0PDysdDqtxsZGzc7Oyu/3y+PxFKNeW7Gs\nJADABB7Lsiyni5BKb+qScC4O+mw/plztR4+vsfPftJ3f52xHzUtNa7MICQAAhiGcAQAwDOEMAIBh\nCGcAAAyT925tAAAKZVtPg/aOHnC6jBXZ1tNQ9OcknAEARfP7F39Vkndra9cvCj7uUpjWBgDAMFw5\nA8Aq2LWiIKsJQiKcAWBVWFEQdmJaGwAAwxDOAAAYhnAGAMAwhDMAAIYhnAEAMAzhDACAYQhnAAAM\nQzgDAGAYwhkAAMMQzgAAGIZwBgDAMIQzAACGIZwBADAM4QwAgGEIZwAADEM4AwBgGMIZAADDEM4A\nABiGcAYAwDA+pwsAUHhbtjyk06enCj7u5s33aWzsVMHHBXA9whlwoZUEaFVVhS5evGRjNQBWimlt\nAAAMQzgDAGAYwhkAAMPwnjNuWTi8QXNzc7aNX1VVUfAxA4GAzpz5R8HHBYBCyBvO2WxW7e3tmp6e\nVllZmTo7O1VdXS1JSiQS2r9/f27fqakptba2qr6+XocOHdLMzIwWFha0Z88ePfbYY/adBRw1Nzdn\n2w1FweB6JRKXCz6uHYEPAIWSN5xHRka0sLCgwcFBxWIxdXd3q6+vT5IUDAY1MDAgSZqcnFRvb68a\nGhr03nvvKRAIqKenR3Nzc3r66acJZwAAlilvOE9MTCgajUqSamtrFY/Hb9jHsix1dHTo6NGj8nq9\neuKJJ/T444/nHvN6vQUuGwAA98obzqlUSn6/P7ft9XqVyWTk8107dHR0VDU1NQqFQpKkO++8M3fs\n888/rxdeeCFvIZWV5fL5SivEg8H1TpdgDDt7YdfY/PyuoRf2o8fX8Psiv7zh7Pf7NT8/n9vOZrPX\nBbMkDQ0NqaWl5br/d/78ee3du1c7d+7UU089lbeQZDK93JqNYcd7oaXKrl7Y9Z6zxM/vv9EL+9Hj\na/h98ZWlAj9vOEciEZ08eVLbt29XLBZTOBy+YZ94PK5IJJLb/uKLL7R79261tbXp4YcfXmXZAAA3\nKrUbMgOBQNGfM28419XVaXx8XE1NTbIsS11dXRoeHlY6nVZjY6NmZ2fl9/vl8Xhyx/T39+vSpUs6\nduyYjh07Jkl64403tG7dOvvOBABgPDuXinXTUrQey7Isp4uQSm/Kx01/CW6Vnb2w86NU/Py+Qi/s\nR4+Lo9T6vNS0NiuEAQBgGNevEGbn6lV2vW/C6lUAcHtzfTjbtXqVnXcFltrNEgCAwmJaGwAAw7j+\nyhn229bToL2jB5wuY0W29TQ4XQIA3BThjFv2+xd/VZJ3a2vXLwo+LgAUAtPaAAAYhnAGAMAwhDMA\nAIYhnAEAMAzhDACAYbhbGwD+jRUFYQrCGQD+jRUFYQqmtQEAMAzhDACAYQhnAAAMQzgDAGAYwhkA\nAMMQzgAAGMb1H6Xi6wwBAKXG9eFs19cZ2v65Rb7OEABuW0xrAwBgGMIZAADDEM4AABiGcAYAwDCu\nvyEMxVFqi+8HAgGnSwCAmyKcccvsuBv+P6qqKmwdHwBMxLQ2AACGIZwBADAM4QwAgGF4zxkoEeHw\nBs3Nzdkyth039AUCAZ0584+Cj2snlvuFKQhnoETMzc2V1FK0pXYHv8RyvzAH09oAABiGcAYAwDCE\nMwAAhsn7nnM2m1V7e7ump6dVVlamzs5OVVdXS5ISiYT279+f23dqakqtra1qbGy86TEAAGBpecN5\nZGRECwsLGhwcVCwWU3d3t/r6+iRJwWBQAwMDkqTJyUn19vaqoaFhyWOcUGo3prC0JADc3vKG88TE\nhKLRqCSptrZW8Xj8hn0sy1JHR4eOHj0qr9e7rGOKxa6lH1lWEgBgl7zhnEql5Pf7c9ter1eZTEY+\n37VDR0dHVVNTo1AotOxj/ldlZbl8Pu+qTsIpweB6p0u4LdDna+zqRamNa6dS7EUp9tkubulF3nD2\n+/2an5/PbWez2RtCdmhoSC0tLSs65n8lk+llF20Kuz63iOvR52vs6IWdn8EtxZ9dqfVYKs0+26WU\nerHUC4m8d2tHIhGNjY1JkmKxmMLh8A37xONxRSKRFR0DAAD+f3mvnOvq6jQ+Pq6mpiZZlqWuri4N\nDw8rnU6rsbFRs7Oz8vv98ng8Sx4DAACWx2NZluV0EVJpTUVI3BBWLPT5Grt6YefynaX2syu1Hkul\n2We7lFovbmlaGwAAFBfhDACAYfhWKgD4LyxaBBMQzgDwbyxaBFMwrQ0AgGG4cgZKxLaeBu0dPeB0\nGcu2rafB6RKAkkU4AyXi9y/+qqQ+5lNVVSHt+kXBxwVuB0xrAwBgGMIZAADDEM4AABiGcAYAwDCE\nMwAAhiGcAQAwDOEMAIBhCGcAAAxDOAMAYBjCGQAAwxDOAAAYhrW1AQBG2rLlIZ0+PbWiY5b7fdyb\nN9+nsbFTqymrKAhnAICRVhqedn2JixOY1gYAwDCEMwAAhmFaGyghy30/zQSBQMDpEoCSRTgDJeLi\nxUu2jFtVVWHb2ABWh2ltAAAMQzgDAGAYwhkAAMMQzgAAGIZwBgDAMIQzAACGIZwBADAM4QwAgGEI\nZwAADMMKYSi6lX4NnFu+Ag4AlitvOGezWbW3t2t6elplZWXq7OxUdXV17vGPP/5Y3d3dsixLwWBQ\nPT09WrNmjV566SXNzMxozZo16ujo0KZNm2w9EZSOlQSom74CDgCWK++09sjIiBYWFjQ4OKjW1lZ1\nd3fnHrMsS4cPH9ZPf/pTnThxQtFoVDMzM/rTn/6kTCajt99+W3v37tWrr75q60kAAOAmea+cJyYm\nFI1GJUm1tbWKx+O5xz777DMFAgEdP35cn3zyibZu3apQKCTLsnT16lVls1mlUin5fMyeAwCwXHlT\nM5VKye/357a9Xq8ymYx8Pp+SyaQmJyfV1tamDRs26LnnntP999+vr3/965qZmdGTTz6pZDKp/v7+\nvIVUVpbL5/Pe2tkUWTC43ukSbgv02X702H70uDjc0ue84ez3+zU/P5/bzmazuSvhQCCg6urq3PvJ\n0WhU8Xhcf/zjH/XII4+otbVV58+f165duzQ8PKy1a9fe9HmSyfStnkvR8V6o/XjPuTjosf3osf1K\n7ffFUi8k8r7nHIlENDY2JkmKxWIKh8O5x+69917Nz8/r7NmzkqSPPvpINTU1qqio0Pr1Xz3pXXfd\npUwmo6tXr97SSQAAcLvIe+VcV1en8fFxNTU1ybIsdXV1aXh4WOl0Wo2NjXrllVfU2toqy7L0wAMP\n6NFHH9U3v/lNHTp0SDt37tTi4qL27dun8vLyYpwPAAAlz2NZluV0EZIZUz4r/fztSvAZ3NUptWmq\nUlRVVaGLFy85XYar0ePiKLXfF0tNa3Mb9X/h87cAlovFdGAnwhkAVoEX87ATa2sDAGAYwhkAAMMQ\nzgAAGIZwBgDAMIQzAACGIZwBADAM4QwAgGEIZwAADEM4AwBgGMIZAADDEM4AABiGcAYAwDCEMwAA\nhiGcAQAwDOEMAIBhCGcAAAxDOAMAYBjCGQAAwxDOAAAYxud0AQAKb8uWh3T69NSy96+qqljWfps3\n36exsVOrLQvAMhHOgAutJECDwfVKJC7bWA2AlWJaGwAAwxDOAAAYhnAGAMAwhDMAAIYhnAEAMAzh\nDACAYQhnAAAMQzgDAGAYwhkAAMMQzgAAGIZwBgDAMIQzAACGyfvFF9lsVu3t7ZqenlZZWZk6OztV\nXV2de/zjjz9Wd3e3LMtSMBhUT0+P1q5dq9dff12jo6NaXFzUjh079Mwzz9h6IgAAuEXecB4ZGdHC\nwoIGBwcVi8XU3d2tvr4+SZJlWTp8+LB+9rOfqbq6Wr/+9a81MzOjRCKhyclJnThxQleuXNGbb75p\n+4kAAOAWecN5YmJC0WhUklRbW6t4PJ577LPPPlMgENDx48f1ySefaOvWrQqFQvrtb3+rcDisvXv3\nKpVK6cCBA/adAQAALpM3nFOplPx+f27b6/Uqk8nI5/MpmUxqcnJSbW1t2rBhg5577jndf//9SiaT\nOnfunPr7+/X5559rz549ev/99+XxeG76PJWV5fL5vIU5qyIJBtc7XcJtgT7bjx7bjx4Xh1v6nDec\n/X6/5ufnc9vZbFY+31eHBQIBVVdXa9OmTZKkaDSqeDyuQCCgUCiksrIyhUIhrV27VrOzs7rnnntu\n+jzJZPpWz6Wo+IL64qDP9qPH9qPHxVFqfV7qhUTeu7UjkYjGxsYkSbFYTOFwOPfYvffeq/n5eZ09\ne1aS9NFHH6mmpkYPPvigPvjgA1mWpQsXLujKlSsKBAK3eh4AANwW8l4519XVaXx8XE1NTbIsS11d\nXRoeHlY6nVZjY6NeeeUVtba2yrIsPfDAA3r00UclSR9++KHq6+tlWZba2trk9ZbWlDUAAE7xWJZl\nOV2EpJKaipBKb/qkVNFn+9Fj+9Hj4ii1Pt/StDYAACguwhkAAMMQzgAAGIZwBgDAMIQzAACGIZwB\nADAM4QwAgGEIZwAADEM4AwBgGMIZAADDGLN8JwAA+ApXzgAAGIZwBgDAMIQzAACGIZwBADAM4QwA\ngGEIZwAADEM4r9Lf/vY3NTc3O12GKy0uLurFF1/Uzp07VV9frz/84Q9Ol+RKV69e1csvv6ympibt\n2LFDZ86ccbok1/ryyy+1detWffrpp06X4krf+9731NzcrObmZr388stOl1MQPqcLKEVvvPGGhoaG\ndMcddzhdiisNDQ0pEAiop6dHc3Nzevrpp/XYY485XZbrnDx5UpL09ttv69SpU+rt7VVfX5/DVbnP\n4uKi2tratG7dOqdLcaV//etfsixLAwMDTpdSUFw5r8KGDRv02muvOV2Gaz3xxBP60Y9+JEmyLEte\nr9fhitzp29/+tjo6OiRJ586dU0VFhcMVudORI0fU1NSkqqoqp0txpdOnT+vKlSvavXu3WlpaFIvF\nnC6pIAjnVXj88cfl8zHpYJc777xTfr9fqVRKzz//vF544QWnS3Itn8+ngwcPqqOjQ0899ZTT5bjO\nu+++q7vvvlvRaNTpUlxr3bp1evbZZ/XLX/5SP/nJT/TjH/9YmUzG6bJuGeEMI50/f14tLS367ne/\nS2jY7MiRI/rd736nw4cPK51OO12Oq7zzzjv6y1/+oubmZk1NTengwYNKJBJOl+UqGzdu1He+8x15\nPB5t3LhRgUDAFT3m8g/G+eKLL7R79261tbXp4Ycfdroc13rvvfd04cIF/fCHP9Qdd9whj8ejNWt4\nvV5Ib731Vu7Pzc3Nam9vVzAYdLAi9/nNb36jM2fOqL29XRcuXFAqlXJFj/mXCOP09/fr0qVLOnbs\nWO4OzH/+859Ol+U627Zt09///nd9//vf17PPPqtDhw5x0xJKTn19vS5fvqwdO3Zo37596urqcsXb\njnwrFQAAhuHKGQAAwxDOAAAYhnAGAMAwhDMAAIYhnAEAMAzhDACAYQhnAAAMQzgDAGCY/wMn26PI\nOPZpfQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f103311d890>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ==================================================================\n",
    "# Plots and shit\n",
    "# ==================================================================\n",
    "data = []\n",
    "for key in tractWinPct:\n",
    "    data.append(tractWinPct[key])\n",
    "\n",
    "plt.figure()\n",
    "plt.boxplot(data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
